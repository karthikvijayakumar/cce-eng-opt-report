{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(gradient_descent)=\n",
    "\n",
    "# Gradient descent\n",
    "\n",
    "*Algorithm*\n",
    "\n",
    "1. Set initial point $x_{0}$ to an arbitrary value in $\\mathbb{R}^{n}$\n",
    "2. Update by setting\n",
    "\n",
    "$$\n",
    "    x_{k+1} = x_{k} - \\alpha_{k} \\nabla f(x_{k});    \\alpha_{k} \\epsilon \\mathbb{R}^{+}\n",
    "$$\n",
    "\n",
    "3. Repeat (2) until a stopping criterion is met.\n",
    "\n",
    "    The stopping condition could be either on the function value or on the gradient or the x values themselves\n",
    "\n",
    "There are multiple things to think about with the above algorithm:\n",
    "\n",
    "1. How to choose ${\\alpha_{k}}_{k=1}^{\\infty}$\n",
    "2. Does the above algorithm converge? If so for what choices of ${ \\alpha_{k} }_{k=1}^{\\infty}$ and how fast?\n",
    "\n",
    "\n",
    "## Choosing step size ${\\alpha_{k}}_{k=1}^{\\infty}$\n",
    "\n",
    "Keeping ${\\alpha_{k}}_{k=1}^{\\infty} = \\alpha$ ( fixed ) can be disadavantageous. Ideally we want to adapt $\\alpha$ as the iteration progresses to enable faster convergence.\n",
    "\n",
    "### Line search\n",
    "\n",
    "One possibility is line search\n",
    "\n",
    "$$\n",
    "    \\alpha_{k} = argmin_{\\alpha} f(x_{k} - \\alpha \\nabla f(x_{k}))\n",
    "$$\n",
    "\n",
    "(i.e find the alpha that gives the most minimization at this step )\n",
    "\n",
    "\n",
    "Note that $f(x_{k} - \\alpha \\nabla f(x_{k}))$ is a restriction of $f$. Restrictions of convex functions are convex and hence the above minimization problem for finding $\\alpha_{k}$ is in turn a convex problem. However that can be complex in own right and may not offer analytical or closed form solutions\n",
    "\n",
    "### Backtracking line search ( Armijo rule )\n",
    "\n",
    "One way to tackle the minimization problem is to not find the minimum but find enough drop in $f(x_{k} - \\alpha \\nabla f(x_{k}))$ that we can guarantee convergence\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "Given $\\alpha_{0} >= 0, \\beta, \\eta \\epsilon (0,1)$\n",
    "\n",
    "1. Pick $x_{0}$ arbitrary point in $\\mathbb{R}^{n}$\n",
    "2. Set $\\alpha_{k} = \\alpha_{0} \\beta^{i}$ for the smallest integer $i$ such that $x_{k+1} = x_{k} - \\alpha_{k} \\nabla f(x_{k})$ satisfies\n",
    "\n",
    "$$\n",
    "    f(x_{k+1}) <= f(x_{k}) - \\frac{1}{2} \\alpha_{k} \\Vert \\nabla f(x_{k}) \\Vert_{2}^{2}\n",
    "$$\n",
    "\n",
    "One could ask does there need to exist $i$ that satisfies the condition in step 2? In general it might not be feasible. If one assumes that $\\nabla f$ is Lipschitz continuous then one can show the existence of a suitable $i$ for each iteration. This is covered under Lemma 1.2 in the following section."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "source_map": [
   10
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}